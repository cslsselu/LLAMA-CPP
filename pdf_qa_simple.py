import streamlit as st
import tempfile
import PyPDF2
from llama_cpp import Llama
import re

def extract_pdf_text(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as f:
        reader = PyPDF2.PdfReader(f)
        for page in reader.pages:
            page_text = page.extract_text() or ""
            text += page_text + " "
    # Replace multiple newlines and excessive whitespace with a single space
    cleaned_text = re.sub(r"\s+", " ", text)
    return cleaned_text.strip()

def ask_llama(prompt):
    llm = Llama(
        model_path="mistral-7b-instruct-v0.1.Q2_K.gguf",
        n_ctx=32768,  # Use full model context
        n_threads=8,
        n_gpu_layers=35,
        verbose=False,
    )
    output = llm(prompt, max_tokens=1024, stop=["</s>"])
    print("************** RAW OUTPUT **************")
    print(output)
    # More robust output handling
    try:
        answer = output['choices'][0]['text'].strip()
        if not answer:
            answer = "[No answer generated by model.]"
    except Exception as e:
        print(f"Error extracting answer: {e}")
        answer = "[Error extracting answer from model output.]"
    return answer

st.title("Simple PDF Q&A (No Chunking)")

uploaded_file = st.file_uploader("Upload a PDF", type=["pdf"])

question = st.text_input("Ask a question about the PDF:")

ask_button = st.button("Ask Question")

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        pdf_path = tmp_file.name
    st.success("PDF uploaded successfully!")
    pdf_text = extract_pdf_text(pdf_path)
    if ask_button and question:
        with st.spinner("Generating answer..."):
            prompt = f"Answer the question based on the following PDF content.\nPDF Content:\n{pdf_text}\nQuestion: {question}\nAnswer:"
            print("##########")
            print(prompt)
            answer = ask_llama(prompt)
            if not answer or answer.strip() == "[No answer generated by model.]":
                st.warning("No answer generated by the model. Try rephrasing your question or check the PDF content.")
            else:
                st.markdown(f"**Answer:** {answer}")
else:
    st.info("Please upload a PDF to enable Q&A.")
